---
title: "PCA, KNN and FDA implementation"
author: "Silvana Alvarez - Sergio Quintanilla"
date: "2025-03-12"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries, warning=FALSE, results='hide'}
#install.packages("OpenImageR")
library(OpenImageR)
library(dplyr)
library(ggplot2)
library(patchwork)
```

```{r functions}
source("function_loading.R")
```


# Part A

Implement a facial recognizer based on Principal Component Analysis. 

**Solution:**

First we show how we create the DB, then in each section we show the functions that we made to create the PCA, KNN and tune the parameters. Finally, we display the application of all the steps using the tuned parameters. 


```{r DB}
# Files
Files = list.files(path="Training/")

# Labels
labels <- as.numeric(gsub("[^0-9]", "", Files))

# Data Base
X = matrix(NA, nrow=150, ncol = 108000)

for(i in seq_along(Files)){
  Im = readImage(paste0("Training/",Files[i]))
  ri=as.vector(Im[,,1])
  gi=as.vector(Im[,,2])
  bi=as.vector(Im[,,3])
  X[i,] = cbind(ri,gi,bi)
}
dim(X)
```

With the previous process we obtain a matrix of 150 rows (images), and 108.000 columns, that represents each pixel of the image, in each one of the RGB colors.

## A)

Build a function that implements the Principal Component Analysis. This function takes as input a set of observations and returns the mean of these observations, the matrix P containing the eigenvectors and a vector D containing the variance explained by each principal axis. It is only allowed to use the function eigen. 

**Solution:**

We create a function where we implement the following steps:

```{r}
PCA
```

Then a small one to project the train and test data, taking into account the PCA made over the train data before:

```{r}
project_pca
```


## B)

Built a classifier (function) that takes as input an image and an object with the parameters of the classifier. Internally, the function uses a k-nn classifier and the PCA representation of the images. If the person in the image belongs to the database, it returns the person’s identifiers. Otherwise it returns 0. In order to build this, you will need to consider:

- The percentage of the variance retaining by the PCs
- The number of neighbors of the k-nn
- The similarity metric
- The threshold to determine when the person belongs to the database

**Solution:**

To begin, we define a special function to define the train/test split. 

First we take some labels out in order to define the "impostors" and be allowed to test the threshold to determine when the person belongs to the database.

With the remaining labels we take some images to the test split (that are also in the train) in order to train the KNN as is normally done.

Finally we join the observations obtained in the two previous steps and define them as the test dataset. The remaining observations are going to be the train dataset. 

```{r}
create_train_test_split
```

With that done, we define the KNN for different possible types of distances (Mahalanobis, SSE Modified and W angle) (creo que hay que poner cita y no se si imprimir las distancias o ponerlas en latex). 

```{r}
knn_classifier
```

## C)

Explain how you have determined the previous parameters

**Solution:**

We made a tuning function where a grid search is done for selecting the parameters:

- K: Number of neighbors
- percent_thresholds: How far is going to be the threshold from the within distances taking into account the between distances
- n_components: How many components of the PCA we are going to keep taking into account the \% of variance explained


```{r, eval=FALSE}
# Define parameter grid for tuning
n_comp_thresholds <- c(0.80, 0.85, 0.90, 0.95)  # Cumulative variance thresholds for PCA
k_values <- c(1, 3, 5)  # Number of neighbors for KNN
percent_thresholds <- c(0.1, 0.2, 0.3)  # Thresholds for novel person detection
num_splits <- 5  # Number of cross-validation splits
num_persons_out <- 2  # Number of persons to leave out for testing

results <- lppo_tuning(
  data = X, 
  labels = labels,
  num_persons_out = num_persons_out,
  n_comp_thresholds = n_comp_thresholds,
  k_values = k_values,
  percent_thresholds = percent_thresholds,
  num_splits = num_splits
)
```

```{r eval=FALSE}
results %>% saveRDS("results_pca_tunning.RDS")
```

```{r warning=FALSE}
results <- readRDS("results_pca_tunning.RDS")

average_distance <- results$avg_results %>% 
  group_by(distance) %>% 
  summarise(av_accuracy = mean(accuracy))

average_results <- results$avg_results %>% 
  group_by(distance, k, n_comp) %>% 
  summarise(av_accuracy = mean(accuracy)) %>% 
  arrange(desc(av_accuracy))

average_distance
average_results %>% head(10)
```

With the previous results we see that the best combination of parameters is:

```{r}
average_results %>% head(1)
```


## D)

Repeat b) but using the initial image representation instead of the principal component representation. Based on your results, decide if you prefer to use the principal component representation or the original representation and justify your decisions.

**Solution:**

## Application

```{r}
# Train test split
split_data <- create_train_test_split(data=X, labels = labels, num_persons_out = 2,
                        split_seed = 782)

train_data <- split_data$train_data
train_labels <- split_data$train_labels

test_data <- split_data$test_data
test_labels <- split_data$test_labels

# PCA model with n_comp found
pca_model <- PCA(train_data, results$n_components)

# Projection of train and test
train_pca <- project_pca(train_data, pca_model)
test_pca <- project_pca(test_data, pca_model)

# Application of the KNN with the parameters tunned
predictions <- knn_classifier(train_data = train_pca, train_labels = train_labels,
                              test_data = test_pca,   k = results$k, 
                              percent_threshold = results$percent_threshold,
                              pca_model = pca_model,  n_comp = results$n_components)

#-------------------------------------------------------------------------------------
# Accuracy of the example
table(predictions$pred, test_labels)

impostors <- names(table(test_labels)[table(test_labels)==6]) # all the images in the test set

correct_predictions <- sum(predictions$pred == test_labels)
correct_impostors <- sum(predictions$pred == 0 & test_labels %in% impostors)

accuracy <- (correct_predictions + correct_impostors) / length(predictions$pred)
cat("accuracy:", accuracy)
```


Also, the distribution of the distances looks as follows:

```{r}
hist(predictions$between, xlim = c(0,1600), col = "lightblue", 
     main="Distances within, between and threshold")
hist(predictions$within, xlim = c(0,1600), col = "yellow", add=T )
abline(v=predictions$thres)
```

# PART B

Implement a facial recognizer based on Fisher discriminant analysis.

## A)

Build a function that implements the Fisher Discriminant Analysis. This function takes as input a set of observations and returns the mean of these observations, the matrix P containing the  eigen vector of the appropriate matrix and a vector D containing the variance explained by each fisher discriminant. It is only allowed to use the function eigen. 

**Solution:**

```{r}
Fisher
```

```{r}
project_fisher
```

## B)

Built a classifier (function) that takes as input an image and an object with the parameters of the classifier. Internally, the function uses a k-nn classifier and the Fisher discriminant analysis representation of the images. If the person in the image belongs to the database, it returns the person’s identifiers. Otherwise it returns 0. In order to build this, you will need to consider:

- The percentage of the variance retaining by the Fisher discriminant dimensions
- The number of neighbors of the k-nn
- The similarity metric
- The threshold to determine when the person belongs to the database

**Solution:**

We take our previous train-split and knn classifier functions and reuse them here.


```{r}
create_train_test_split
```


```{r}
knn_classifier
```


## C)

Explain how you have determined the previous parameters

**Solution:**

```{r, eval=FALSE}

# Define parameter grid for tuning
n_comp_thresholds <- c(0.80, 0.85, 0.90, 0.95)  # Cumulative variance thresholds for PCA
k_values <- c(1, 3, 5)  # Number of neighbors for KNN
percent_thresholds <- c(0.1, 0.2, 0.3)  # Thresholds for novel person detection
num_splits <- 5  # Number of cross-validation splits
num_persons_out <- 2  # Number of persons to leave out for testing

PCA_model = PCA(X,150)
proj = project_pca(X,PCA_model)[,1:20]

# Run the tuning function
source("function_loading.R")

tuning_results_fisher <- lppo_tuning_FISHER(
  data = proj, 
  labels = labels,
  num_persons_out = num_persons_out,
  n_comp_thresholds = n_comp_thresholds,
  k_values = k_values,
  percent_thresholds = percent_thresholds,
  num_splits = num_splits
)

```

```{r,eval=FALSE}
tuning_results_fisher %>% saveRDS("results_fisher_tuning.RDS")

```

```{r eval=FALSE}
tuning_results_fisher
```


```{r eval=FALSE}
# Produce a full dataset PCA to use as our base Fisher data
pca_model <- PCA(X, results$n_components)
proj= project_pca(X,pca_model)

# Train test split
split_data <- create_train_test_split(data=proj, labels = labels, num_persons_out = 2,
                        split_seed = 782)

train_data <- split_data$train_data
train_labels <- split_data$train_labels

test_data <- split_data$test_data
test_labels <- split_data$test_labels
dim(train_data)
train_labels
train_data
# Declare Fisher model
f_model = Fisher(train_data,train_labels)

# Projection of train and test
train_f <- project_fisher(train_data, f_model)
test_f <- project_fisher(test_data, f_model)



predictions <- knn_classifier(train_data = train_f, train_labels = train_labels,
                              test_data = test_data,   k = tuning_results_fisher$k, 
                              percent_threshold = tuning_results_fisher$percent_threshold,
                              pca_model = f_model,  n_comp = tuning_results_fisher$n_components)

#-------------------------------------------------------------------------------------
table(predictions$pred, test_labels)

impostors <- names(table(test_labels)[table(test_labels)==6]) # all the images in the test set

correct_predictions <- sum(predictions$pred == test_labels)
correct_impostors <- sum(predictions$pred == 0 & test_labels %in% impostors)

accuracy <- (correct_predictions + correct_impostors) / length(predictions$pred)
accuracy
```



