library(data.table)
install.packages('data.table')
library(data.table)
install.packages('dplyr')
library(dplyr)
install.packages('tidyr')
library(tidyr)
install.packages('ggplot2')
install.packages('shiny')
install.packages('sparklyr')
install.packages('DBI')
install.packages('readr')
install.packages('stellar')
install.packages('stellaR')
install.packages('arrow')
install.packages('xgboost')
install.packages('caret')
install.packages('glmnet')
install.packages('comet')
install.packages('formattable')
install.packages('pleidadis')
install.packages('kableExtra')
install.packages('targets')
install.packages('gt')
install.packages('titanng')
libraries <- c('data.table', 'dplyr', 'tidyr', 'ggplot2', 'shiny', 'sparklyr',
'DBI', 'stellaR', 'readr', 'arrow', 'xgboost', 'caret', 'glmnet',
'comet', 'formattable','pleidadis', 'kableExtra', 'targets',
'lubridate', 'gt', 'titanng')
libraries <- setdiff(libraries, (.packages()))
libraries <- c('data.table', 'dplyr', 'tidyr', 'ggplot2', 'shiny', 'sparklyr',
'DBI', 'stellaR', 'readr', 'arrow', 'xgboost', 'caret', 'glmnet',
'comet', 'formattable','pleidadis', 'kableExtra', 'targets',
'lubridate', 'gt', 'titanng')
libraries <- setdiff(libraries, (.packages()))
sapply(libraries, require, character.only = T)
rm(libraries)
rstudioapi::getSourceEditorContext()$path
rstudioapi::getSourceEditorContext()$path
path_base <- rstudioapi::getSourceEditorContext()$path %>%
dirname() %>%  dirname() %>% file.path('Codigos_TU')
runif(1)
runif(1)
?gainsTable
install.packages('TUISG')
# MODELO XGB
parametros <- list(
eta = 0.1, #aprendizaje lento
max_depth = 2,
min_child_weight = 100, #mÃ¡s grande da menos variables
objective = "binary:logistic",
eval_metric = "auc"
)
install.packages('titanng')
install.packages('TUISG')
R.version
update.packages(ask = FALSE, checkBuilt = TRUE)
install.packages("Matrix")
library(Matrix)
library(np)
install.packages("Matrix", repos = "https://cloud.r-project.org/")
install.packages("remotes")
remotes::install_version("Matrix", version = "1.5-4.1", repos = "https://cloud.r-project.org/")
library(np)
install.packages("devtools")
devtools::install_github("cran/Matrix")
R.version
update.packages(ask = FALSE, checkBuilt = TRUE)
library(Matrix)
library(np)
install.packages("Matrix")
install.packages("Matrix")
install.packages("devtools")
devtools::install_github("cran/Matrix")
R.version
Files = list.files(path="../Training/")
X = matrix(NA, nrow=150, ncol = 108000)
for(i in seq_along(Files)){
Im = readImage(paste0("../Training/",Files[i]))
ri=as.vector(Im[,,1])
gi=as.vector(Im[,,2])
bi=as.vector(Im[,,3])
X[i,] = cbind(ri,gi,bi)
}
dim(X)
pca <- PCA(X,30)
proj <- project_pca(X, pca)
mahalanobis_distance <- function(test_point, train_data, pca_model, n_comp) {
inv_cov <- diag(1/pca_model$values[1:n_comp]) # Compute inverse covariance matrix
# Compute Mahalanobis distance for each training sample
distances <- apply(train_data, 1, function(row) {
diff <- row - test_point  # Element-wise subtraction
sqrt(t(diff) %*% inv_cov %*% diff)  # Mahalanobis distance formula
})
return(distances)
}
PCA <- function(X_train, n_comp){
M <- colMeans(X_train)    # Mean
G <- X_train - M          # Centered Data
G_ <- t(G)                # Transpose centered data
n_train <- nrow(X_train)        # Number of train observations
Sigma_s <- (G%*%G_)/(n_train-1) # Compute Sigma small
eig=eigen(Sigma_s)        # Obtain Sigma_small eigen vectors/values
e_vec_s=eig$vectors       # select eigen vector of sigma small
P = G_%*%e_vec_s          # Eigen vectors of Sigma_large
L = diag(eig$values)      # Diagonal matrix of eigenvalues
D =  round(eig$values / sum(eig$values),3) # Prop of variance explained
# Select top principal components
top_comp <- P[, 1:n_comp]
# Return PCA components and mean for projection
list(components = top_comp, mean = M, vectors = P,
values = eig$values, var_exp = D)
}
# Function to project data onto PCA space
project_pca <- function(data, pca_model) {
centered_data <- data - pca_model$mean # Center the data
projected_data <- as.matrix(centered_data) %*% pca_model$components
return(projected_data)
}
pca <- PCA(X,30)
setwd("C:/Users/Usuario/Desktop/Git/StatisticalLearning/Pruebas_silvana")
setwd("C:/Users/Usuario/Desktop/Git/StatisticalLearning/Pruebas_silvana")
Files = list.files(path="../Training/")
# Files
X = matrix(NA, nrow=150, ncol = 108000)
for(i in seq_along(Files)){
Im = readImage(paste0("../Training/",Files[i]))
ri=as.vector(Im[,,1])
gi=as.vector(Im[,,2])
bi=as.vector(Im[,,3])
X[i,] = cbind(ri,gi,bi)
}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("OpenImageR")
library(OpenImageR)
library(dplyr)
library(ggplot2)
for(i in seq_along(Files)){
Im = readImage(paste0("../Training/",Files[i]))
ri=as.vector(Im[,,1])
gi=as.vector(Im[,,2])
bi=as.vector(Im[,,3])
X[i,] = cbind(ri,gi,bi)
}
dim(X)
pca <- PCA(X,30)
proj <- project_pca(X, pca)
m_dist <- matrix(NA, nrow(X), nrow(X))
for (i in 1:nrow(X)) {
test_point <- proj[i,]  # Example: using the 10th image as a query
m_dist[i,] <-mahalanobis_distance(test_point, proj, pca, n_comp=30)
}
summary(m_dist)
hist(m_dist)
quantile(m_dist, seq(0.6,1,0.05))
labels <- as.numeric(gsub("[^0-9]", "", Files))
X_df<- cbind(labels, X)
g_means <- X_df %>% group_by(labels) %>% summarise(mean = colMeans(X[,2:ncol(X)]))
g_means <- X_df %>% group_by(labels) %>% summarise(across(everything(), mean, na.rm = TRUE))
X_df<- as.data.frame(cbind(labels, X))
g_means <- X_df %>% group_by(labels) %>% summarise(across(everything(), mean, na.rm = TRUE))
m_dist <- matrix(NA, nrow(X), nrow(X))
for (i in 1:nrow(X)) {
test_point <- proj[i,]  # Example: using the 10th image as a query
m_dist[i,] <-mahalanobis_distance(test_point, proj, pca, n_comp=20)
}
pca <- PCA(X,20)
proj <- project_pca(X, pca)
m_dist <- matrix(NA, nrow(X), nrow(X))
for (i in 1:nrow(X)) {
test_point <- proj[i,]  # Example: using the 10th image as a query
m_dist[i,] <-mahalanobis_distance(test_point, proj, pca, n_comp=20)
}
summary(m_dist)
hist(m_dist)
quantile(m_dist, seq(0.6,1,0.05))
pca <- PCA(X, n_comp=150)
proj <- project_pca(X, pca)
m_dist <- matrix(NA, nrow(X), nrow(X))
for (i in 1:nrow(X)) {
test_point <- proj[i,]  # Example: using the 10th image as a query
m_dist[i,] <-mahalanobis_distance(test_point, proj, pca, n_comp=150)
}
summary(m_dist)
hist(m_dist)
quantile(m_dist, seq(0.6,1,0.05))
labels <- as.numeric(gsub("[^0-9]", "", Files))
X_df<- as.data.frame(cbind(labels, proj))
g_means <- X_df %>% group_by(labels) %>% summarise(across(everything(), mean, na.rm = TRUE))
g_means
m_dist_g <- matrix(NA, nrow(g_means), nrow(g_means))
for (i in 1:nrow(X)) {
test_point <- g_means[i,]  # Example: using the 10th image as a query
m_dist[i,] <-mahalanobis_distance(test_point, proj, pca, n_comp=150)
}
euclidean_distance <- function(test_point, train_data) {
distances <- apply(train_data, 1, function(row) {
sqrt(sum((row - test_point)^2))  # Euclidean distance formula
})
return(distances)
}
#   MAHALANOBIS
#-----------------
mahalanobis_distance <- function(test_point, train_data, pca_model, n_comp) {
inv_cov <- diag(1/pca_model$values[1:n_comp]) # Compute inverse covariance matrix
# Compute Mahalanobis distance for each training sample
distances <- apply(train_data, 1, function(row) {
diff <- row - test_point  # Element-wise subtraction
sqrt(t(diff) %*% inv_cov %*% diff)  # Mahalanobis distance formula
})
return(distances)
}
sse_mod_distance <- function(test_point, train_data) {
distances <- apply(train_data, 1, function(row) {
sum((row - test_point)^2)/(sum((row)^2)*sum((test_point)^2))  # Euclidean distance formula
})
return(distances)
}
w_angle_distance <- function(test_point, train_data, pca_model, n_comp) {
lambda <- pca_model$values[1:n_comp]
z <- (1/lambda) # Compute inverse covariance matrix
# Compute Mahalanobis distance for each training sample
distances <- apply(train_data, 1, function(row) {
numerator <- sum(z*row*test_point)
denominator <- sqrt(sum(row^2)*sum(test_point^2))
- numerator/denominator
})
return(distances)
}
#   MAHALANOBIS
#-----------------
mahalanobis_distance <- function(test_point, train_data, pca_model, n_comp) {
inv_cov <- diag(1/pca_model$values[1:n_comp]) # Compute inverse covariance matrix
# Compute Mahalanobis distance for each training sample
distances <- apply(train_data, 1, function(row) {
diff <- row - test_point  # Element-wise subtraction
sqrt(t(diff) %*% inv_cov %*% diff)  # Mahalanobis distance formula
})
return(distances)
}
euclidean_distance <- function(test_point, train_data) {
distances <- apply(train_data, 1, function(row) {
sqrt(sum((row - test_point)^2))  # Euclidean distance formula
})
return(distances)
}
sse_mod_distance <- function(test_point, train_data) {
distances <- apply(train_data, 1, function(row) {
sum((row - test_point)^2)/(sum((row)^2)*sum((test_point)^2))  # Euclidean distance formula
})
return(distances)
}
w_angle_distance <- function(test_point, train_data, pca_model, n_comp) {
lambda <- pca_model$values[1:n_comp]
z <- (1/lambda) # Compute inverse covariance matrix
# Compute Mahalanobis distance for each training sample
distances <- apply(train_data, 1, function(row) {
numerator <- sum(z*row*test_point)
denominator <- sqrt(sum(row^2)*sum(test_point^2))
- numerator/denominator
})
return(distances)
}
# Mahalanobis distance
euclidean_dist <- matrix(NA, nrow(X), nrow(X))
# Mahalanobis distance
euclidean_dist <- matrix(NA, nrow(X), nrow(X))
for (i in 1:nrow(X)) {
test_point <- proj[i,]  # Example: using the 10th image as a query
euclidean_dist[i,] <-euclidean_dist(test_point, proj)
}
for (i in 1:nrow(X)) {
test_point <- proj[i,]  # Example: using the 10th image as a query
euclidean_dist[i,] <-euclidean_distance(test_point, proj)
}
summary(euclidean_dist)
hist(euclidean_dist)
quantile(euclidean_dist, seq(0.6,1,0.05))
seq(42150, 55600, by = 50)
seq(42100, 55600, by = 100)
seq(42200, 55600, by = 200)
seq(1450, 1800, by = 50)
seq(42000, 56000, by = 500)
seq(42000, 56000, by = 1000)
quantile(euclidean_dist, seq(0.6,1,0.05))
#   SSE Modified distance
#--------------------------
sse_mod_dist <- matrix(NA, nrow(X), nrow(X))
for (i in 1:nrow(X)) {
test_point <- proj[i,]  # Example: using the 10th image as a query
sse_mod_dist[i,] <-sse_mod_distance(test_point, proj)
}
summary(sse_mod_dist)
hist(sse_mod_dist)
quantile(sse_mod_dist, seq(0.6,1,0.05))
seq(3.429218e-10, 2.147565e-09, by = 2.147565e-02)
seq(3.429218e-10, 2.147565e-09, by = 2.147565e-03)
seq(3.429218e-10, 2.147565e-09, by = 2.147565e-08)
seq(3.429218e-10, 2.147565e-09, by = 1e-010)
seq(3.429218e-10, 2.147565e-09, by = 2e-010)
seq(3.4e-10, 2.2e-09, by = 2e-010)
#  Weighted Angle-based distance
#----------------------------------
w_angle_dist <- matrix(NA, nrow(X), nrow(X))
for (i in 1:nrow(X)) {
test_point <- proj[i,]  # Example: using the 10th image as a query
w_angle_dist[i,] <-w_angle_distance(test_point, proj, pca, n_comp=150)
}
summary(w_angle_dist)
hist(w_angle_dist)
quantile(w_angle_dist, seq(0.6,1,0.05))
seq(-2e-04, 2e-04, by = 1e-04)
threshold_mahalanobis
threshold_mahalanobis <- seq(1450, 1800, by = 50)
threshold_mahalanobis
seq(-1.5e-04, 2e-04, by = .5e-04)
